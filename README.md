## NLP project: How does a Transformer solve a task
__Goal:__ discover attention patterns in a trained model
__Tasks:__ 
- research visualization methods
- pretrain a seq2seq Transformer on a downstream task
- visualize and interpret attention patterns 


**Input:** pretrained model, task source and target

**Output:** visual schemes, insights


### Basic solution: heatmap of attention maps

### Influence:
cutting-edge research with modern models
deep insights into neural attention
